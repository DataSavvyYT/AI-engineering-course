{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataSavvyYT/AI-engineering-course/blob/main/04_mcp/04_mcp_with_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mcp openai nest_asyncio"
      ],
      "metadata": {
        "id": "430zhOo5Powm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "tHSCVd-NqFQY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Apply the patch allows nested async loops in Colab\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "sXsHt59gp_Ks"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile converter.py\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "import logging\n",
        "\n",
        "# 1. Setup Server (Silence info logs)\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "mcp = FastMCP(\"UnitConverter\")\n",
        "\n",
        "# 2. Define Tool: Feet to Meters\n",
        "@mcp.tool()\n",
        "def feet_to_meters(feet: float) -> float:\n",
        "    \"\"\"Converts a length from feet to meters.\"\"\"\n",
        "    return feet * 0.3048\n",
        "\n",
        "# 3. Define Tool: Meters to Feet\n",
        "@mcp.tool()\n",
        "def meters_to_feet(meters: float) -> float:\n",
        "    \"\"\"Converts a length from meters to feet.\"\"\"\n",
        "    return meters / 0.3048\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mcp.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq6HKkaqoqT0",
        "outputId": "0db978b3-e18e-4663-d23e-dfca8d7e72db"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing converter.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import sys\n",
        "import nest_asyncio\n",
        "from openai import OpenAI\n",
        "from mcp import ClientSession, StdioServerParameters\n",
        "from mcp.client.stdio import stdio_client\n",
        "\n",
        "# Apply Colab async fix\n",
        "nest_asyncio.apply()\n",
        "\n",
        "class SimpleMCPAgent:\n",
        "    def __init__(self, server_script, api_key):\n",
        "        self.server_script = server_script\n",
        "        self.client = OpenAI(api_key=api_key)\n",
        "\n",
        "    async def process_query(self, user_query):\n",
        "        \"\"\"Connects to server, gets tools, asks AI, and runs the tool.\"\"\"\n",
        "\n",
        "        # 1. SERVER CONFIG (The \"-u\" flag is vital for Colab!)\n",
        "        server_params = StdioServerParameters(\n",
        "            command=sys.executable,\n",
        "            args=[\"-u\", self.server_script],\n",
        "        )\n",
        "\n",
        "        print(f\"üîå Connecting to {self.server_script}...\")\n",
        "\n",
        "        async with stdio_client(server_params) as (read, write):\n",
        "            async with ClientSession(read, write) as session:\n",
        "                await session.initialize()\n",
        "\n",
        "                # 2. DISCOVER TOOLS (Dynamic!)\n",
        "                tools = await session.list_tools()\n",
        "                openai_tools = [self._convert_tool(t) for t in tools.tools]\n",
        "                print(f\"üõ†Ô∏è  Agent found these tools: {[t.name for t in tools.tools]}\")\n",
        "\n",
        "                # 3. THINK (Ask OpenAI)\n",
        "                messages = [{\"role\": \"user\", \"content\": user_query}]\n",
        "                response = self.client.chat.completions.create(\n",
        "                    model=\"gpt-4o\",\n",
        "                    messages=messages,\n",
        "                    tools=openai_tools\n",
        "                )\n",
        "\n",
        "                # 4. DECIDE & ACT\n",
        "                tool_call = response.choices[0].message.tool_calls[0] if response.choices[0].message.tool_calls else None\n",
        "\n",
        "                if tool_call:\n",
        "                    func_name = tool_call.function.name\n",
        "                    func_args = eval(tool_call.function.arguments)\n",
        "\n",
        "                    print(f\"ü§ñ Agent decided to call: {func_name}({func_args})\")\n",
        "\n",
        "                    # Execute on Server\n",
        "                    result = await session.call_tool(func_name, arguments=func_args)\n",
        "                    print(f\"‚úÖ Tool Result: {result.content[0].text}\")\n",
        "                    return result.content[0].text\n",
        "                else:\n",
        "                    print(\"ü§∑ Agent didn't need a tool.\")\n",
        "                    return response.choices[0].message.content\n",
        "\n",
        "    def _convert_tool(self, tool):\n",
        "        \"\"\"Helper to format MCP tools for OpenAI\"\"\"\n",
        "        return {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": tool.name,\n",
        "                \"description\": tool.description,\n",
        "                \"parameters\": tool.inputSchema\n",
        "            }\n",
        "        }\n",
        "\n",
        "# --- usage ---\n",
        "print(\"Agent Class Ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppmvuyzZrpFi",
        "outputId": "fe8254d6-dde8-4c30-c177-f253f68831e0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent Class Ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "9qtHRVz1uViI"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SETUP: Put your key here\n",
        "API_KEY = OPENAI_API_KEY  # <--- REPLACE WITH YOUR KEY\n",
        "\n",
        "# 2. INITIALIZE\n",
        "agent = SimpleMCPAgent(\"converter.py\", api_key=API_KEY)\n",
        "\n",
        "# 3. ASK A QUESTION\n",
        "query = \"I have a 100 foot rope. How many meters is that?\"\n",
        "result = await agent.process_query(query)"
      ],
      "metadata": {
        "id": "KdijCJwEuQA3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}