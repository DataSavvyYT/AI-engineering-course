{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZDIlavA9ea37pXJlw/lwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataSavvyYT/AI-engineering-course/blob/main/01_llm_tokens/03_llm_tokens_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyjpI7qDOfwI"
      },
      "outputs": [],
      "source": [
        "# --- 1. Install necessary library ---\n",
        "# tiktoken is the official BPE tokenizer for OpenAI models (GPT-3.5, GPT-4, etc.)\n",
        "!pip install tiktoken -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Import Libraries ---\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "8IEouVA-O_3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def visualize_tokens(text, model_encoding=\"cl100k_base\"):\n",
        "    \"\"\"\n",
        "    Splits text into tokens using tiktoken and displays the string representation\n",
        "    of each token, rather than the integer ID.\n",
        "    \"\"\"\n",
        "    # Load the encoding used by GPT-4 and GPT-3.5\n",
        "    encoding = tiktoken.get_encoding(model_encoding)\n",
        "\n",
        "    # Tiktoken requires us to encode to integers first to find boundaries\n",
        "    token_integers = encoding.encode(text)\n",
        "\n",
        "    # Convert those integers back to their individual string/byte representations\n",
        "    # to visualize the actual \"tokens\"\n",
        "    token_strings = [\n",
        "        encoding.decode_single_token_bytes(token).decode(\"utf-8\", errors=\"replace\")\n",
        "        for token in token_integers\n",
        "    ]\n",
        "\n",
        "    print(f\"--- Tokenization Report for: '{model_encoding}' ---\")\n",
        "    print(f\"Original Text:  {text}\\n\")\n",
        "    print(f\"Token Count:    {len(token_strings)}\")\n",
        "    print(f\"Token List:     {token_strings}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # detailed view showing boundaries clearly\n",
        "    print(\"\\nDetailed Boundary View:\")\n",
        "    for i, token in enumerate(token_strings):\n",
        "        print(f\"Token {i+1}: '{token}'\")\n",
        "\n",
        "# --- Example Usage ---\n",
        "sample_text = \"Tokenization is fascinating!\"\n",
        "visualize_tokens(sample_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjvgHF25PFk6",
        "outputId": "37f7b70a-99e9-4248-d9fe-342831992089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tokenization Report for: 'cl100k_base' ---\n",
            "Original Text:  Tokenization is fascinating!\n",
            "\n",
            "Token Count:    5\n",
            "Token List:     ['Token', 'ization', ' is', ' fascinating', '!']\n",
            "--------------------------------------------------\n",
            "\n",
            "Detailed Boundary View:\n",
            "Token 1: 'Token'\n",
            "Token 2: 'ization'\n",
            "Token 3: ' is'\n",
            "Token 4: ' fascinating'\n",
            "Token 5: '!'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Define Input Text Examples ---\n",
        "# Example 1: Standard English sentence\n",
        "text_1 = \"The tokenization demonstration with tiktoken is now complete.\"\n",
        "\n",
        "# Example 2: Numbers, symbols, and a very long/rare word\n",
        "# LLMs are good at splitting these into byte-level subwords.\n",
        "text_2 = \"Hello $1,000,000! Let's analyze the 'unpredictability' of the process.\""
      ],
      "metadata": {
        "id": "g5HEIlOcPLPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "430zhOo5Powm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}