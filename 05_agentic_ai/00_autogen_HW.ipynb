{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataSavvyYT/AI-engineering-course/blob/main/05_agentic_ai/00_autogen_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyautogen autogen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8_Cm7kegfGK",
        "outputId": "97e821ea-0353-4908-b80d-2b92021624cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/910.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m901.1/910.5 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m910.5/910.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/147.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import autogen"
      ],
      "metadata": {
        "id": "BmMrwBBJg09g"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "# Ensure the API key is available\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "8WJQByRfhODu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the LLM Configuration\n",
        "# Replace the key below with your valid OpenAI API key.\n",
        "# You can also use Azure OpenAI or other compatible endpoints.\n",
        "config_list = [\n",
        "    {\n",
        "        \"model\": \"gpt-4o-mini\",\n",
        "        \"api_key\": OPENAI_API_KEY\n",
        "    }\n",
        "]\n",
        "\n",
        "llm_config = {\n",
        "    \"config_list\": config_list,\n",
        "    \"temperature\": 0, # Temperature 0 for deterministic output\n",
        "}"
      ],
      "metadata": {
        "id": "j4gMzpe_g3tH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create an Assistant Agent\n",
        "# This agent acts as the AI assistant that will generate the code/response.\n",
        "assistant = autogen.AssistantAgent(\n",
        "    name=\"assistant\",\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"You are a helpful AI assistant.\"\n",
        ")"
      ],
      "metadata": {
        "id": "J0TaLUZJhaK9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Create a User Proxy Agent\n",
        "# This agent acts on behalf of the user. In this specific 'Hello World' demo,\n",
        "# we set human_input_mode=\"NEVER\" so it runs automatically without pausing for user input.\n",
        "# We also specify code_execution_config to allow it to execute code if necessary\n",
        "# (though for a simple Hello World text, it might not need to).\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"user_proxy\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    max_consecutive_auto_reply=1,  # Limit replies to prevent infinite loops\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
        "    code_execution_config={\n",
        "        \"work_dir\": \"coding\", # Directory where code is written\n",
        "        \"use_docker\": False   # Set to True if you have docker running, False for Colab\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "UO91m83rhdzC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Initiate the Chat\n",
        "# The user proxy starts the conversation with a specific task.\n",
        "print(\"--- Starting AutoGen Hello World Demo ---\")\n",
        "user_proxy.initiate_chat(\n",
        "    assistant,\n",
        "    message=\"Write a Python script that prints 'Hello World from Microsoft AutoGen!', and then output the code.\"\n",
        ")"
      ],
      "metadata": {
        "id": "aJysZgGMhhJj",
        "outputId": "56aa9cb3-7079-411a-b535-cb6a6e2ccb77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting AutoGen Hello World Demo ---\n",
            "user_proxy (to assistant):\n",
            "\n",
            "Write a Python script that prints 'Hello World from Microsoft AutoGen!', and then output the code.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to user_proxy):\n",
            "\n",
            "Here is a simple Python script that prints \"Hello World from Microsoft AutoGen!\":\n",
            "\n",
            "```python\n",
            "# This script prints a greeting message\n",
            "print('Hello World from Microsoft AutoGen!')\n",
            "```\n",
            "\n",
            "You can run this script in any Python environment to see the output.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\n",
            "user_proxy (to assistant):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: \n",
            "Hello World from Microsoft AutoGen!\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant (to user_proxy):\n",
            "\n",
            "Great! It looks like the script executed successfully and printed the desired output:\n",
            "\n",
            "```\n",
            "Hello World from Microsoft AutoGen!\n",
            "```\n",
            "\n",
            "If you have any more questions or need further assistance, feel free to ask!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> TERMINATING RUN (38a9726c-13ba-4d37-a874-dccab21a4c65): Maximum number of consecutive auto-replies reached\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=221949468909951993335382121557161277225, chat_history=[{'content': \"Write a Python script that prints 'Hello World from Microsoft AutoGen!', and then output the code.\", 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'Here is a simple Python script that prints \"Hello World from Microsoft AutoGen!\":\\n\\n```python\\n# This script prints a greeting message\\nprint(\\'Hello World from Microsoft AutoGen!\\')\\n```\\n\\nYou can run this script in any Python environment to see the output.', 'role': 'user', 'name': 'assistant'}, {'content': 'exitcode: 0 (execution succeeded)\\nCode output: \\nHello World from Microsoft AutoGen!\\n', 'role': 'assistant', 'name': 'user_proxy'}, {'content': 'Great! It looks like the script executed successfully and printed the desired output:\\n\\n```\\nHello World from Microsoft AutoGen!\\n```\\n\\nIf you have any more questions or need further assistance, feel free to ask!', 'role': 'user', 'name': 'assistant'}], summary='Great! It looks like the script executed successfully and printed the desired output:\\n\\n```\\nHello World from Microsoft AutoGen!\\n```\\n\\nIf you have any more questions or need further assistance, feel free to ask!', cost={'usage_including_cached_inference': {'total_cost': 8.174999999999998e-05, 'gpt-4o-mini-2024-07-18': {'cost': 8.174999999999998e-05, 'prompt_tokens': 165, 'completion_tokens': 95, 'total_tokens': 260}}, 'usage_excluding_cached_inference': {'total_cost': 8.174999999999998e-05, 'gpt-4o-mini-2024-07-18': {'cost': 8.174999999999998e-05, 'prompt_tokens': 165, 'completion_tokens': 95, 'total_tokens': 260}}}, human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RH8YMfS1hlHC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}